{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Predict House Price.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ogt9hCxg0fV4",
        "colab_type": "text"
      },
      "source": [
        "# Predecir el precio de casas"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbJmvh20fWS",
        "colab_type": "text"
      },
      "source": [
        "# Explorando y procesando nuestros datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jq33gBNh0fWa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DjGdGBpF1fSO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git clone https://github.com/Carlos-Trinidad/predict-house-price.git"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89_1mrXX2D9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! ls"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uIlGAmwz0fWm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.read_csv('predict-house-price/housepricedata.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GY9QjUiR0fWr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "00ACIupS0fW2",
        "colab_type": "text"
      },
      "source": [
        "El dataset que tenemos ahora es lo que se conoce como un pandas dataframe. Para convertirlo en un array, simplemente accedemos a sus valores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bbziPyHJ0fW3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = df.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lF2r3Ajl0fW9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5H7QoGF0fXH",
        "colab_type": "text"
      },
      "source": [
        "Ahora, dividimos el conjunto de datos en input features y la label que deseamos predecir."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hfUluLCZ0fXI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset[:,0:10]\n",
        "Y = dataset[:,10]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gwb4e1Qt0fXP",
        "colab_type": "text"
      },
      "source": [
        "La normalización de nuestros datos es muy importante, ya que queremos que las características de entrada (input features) estén en el mismo orden de magnitud para facilitar nuestro entrenamiento. Usaremos un escalador min-max de scikit-learn que escala nuestros datos para que estén entre 0 y 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UlidOUYZ0fXR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jPU9ONk0fXZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "X_scale = min_max_scaler.fit_transform(X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9iXJo4Ul0fXf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_scale"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "elgg84cr0fXo",
        "colab_type": "text"
      },
      "source": [
        "Por último, deseamos reservar algunas partes de nuestro conjunto de datos para un conjunto de validación y un conjunto de prueba. Usamos la función train_test_split de scikit-learn para realizar esto."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "we_APswa0fXp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l6die1BH0fXu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWsFE86D0fXx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zOxok6z0fX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Spq0hZN0fX_",
        "colab_type": "text"
      },
      "source": [
        "# Creando y entrenando nuestra red neuronal\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OQHaKnNB0fYA",
        "colab_type": "text"
      },
      "source": [
        "Usaremos Keras para construir nuestra arquitectura. Importemos de Keras directamente el código que necesitaremos usar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc0sWtM90fYB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KdwLY7g0fYK",
        "colab_type": "text"
      },
      "source": [
        "Usaremos el modelo Sequential, lo que significa que simplemente necesitamos describir las capas de arriba en secuencia. Nuestra red neuronal tiene tres capas:\n",
        "\n",
        "- Hidden layer 1: 30 neurons, ReLU activation\n",
        "- Hidden layer 2: 30 neurons, ReLU activation\n",
        "- Output Layer: 1 neuron, Sigmoid activation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j6gLXpzN0fYM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Sequential([\n",
        "    Dense(32, activation='relu', input_shape=(10,)),\n",
        "    Dense(32, activation='relu'),\n",
        "    Dense(1, activation='sigmoid'),\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qz1D4OO00fYQ",
        "colab_type": "text"
      },
      "source": [
        "Ahora que tenemos nuestra arquitectura especificada, necesitamos encontrar los mejores números para ella. Antes de comenzar nuestro entrenamiento, tenemos que configurar el modelo por\n",
        "- Decirle qué algoritmo desea usar para hacer la optimización (utilizaremos stochastic gradient descent)\n",
        "- Decirle qué función de pérdida usar (loss function) (para la clasificación binaria, usaremos binary cross entropy)\n",
        "- Decirle qué otras métricas desea rastrear aparte de la función de pérdida (también queremos rastrear la accuaracy)\n",
        "\n",
        "Lo hacemos a continuación:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW_TpH030fYS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yeJKxBcm0fYX",
        "colab_type": "text"
      },
      "source": [
        "Para entrenar nuestro módelo con nuestros datos es bastante sencillo y requiere escribir solo una línea de código. La funcion se llama \"fit\" y en ella específicaremos:\n",
        "- que datos estamos entrenando, los cuales son X_train y Y_train\n",
        "- el tamaño de nuestro mini-batch\n",
        "- por cuanto tiempo queremos entrenarlo (epochs)\n",
        "- cuáles son nuestros datos de validación para que el modelo nos diga cómo lo estamos haciendo en los datos de validación de cada punto.\n",
        "\n",
        "Esta función generará un historial, que guardaremos bajo la variable hist. Usaremos esta variable un poco más adelante."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8vFIqZvu0fYa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "hist = model.fit(X_train, Y_train,\n",
        "          batch_size=32, epochs=100,\n",
        "          validation_data=(X_val, Y_val))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6wC6hkk0fYg",
        "colab_type": "text"
      },
      "source": [
        "Evaluamos nuestro modelo con nuestro test set:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWCu688i0fYh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test, Y_test)[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zBcIO0Zs7kHB",
        "colab_type": "text"
      },
      "source": [
        "La razón por la que tenemos el índice 1 después de la función model.evaluate es porque la función devuelve el loss como el primer elemento y el accuracy como el segundo elemento. Para obtener solo la precisión (accuracy), simplemente accedemos al segundo elemento (que está indexado por 1, ya que el primer elemento comienza su indexación desde 0).\n",
        "\n",
        "A continuación podemos ver cómo nos devolvería los dos valores:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_scMmwAU7-hN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.evaluate(X_test, Y_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sQQSw9Xq_4Qh",
        "colab_type": "text"
      },
      "source": [
        "Por último, también podemos ver como es la predicción de nuestro modelo con cada uno de nuestros datos de test:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVb25Xw_8dAK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "40AWr0XE0fYl",
        "colab_type": "text"
      },
      "source": [
        "# Visualizando el Loss y Accuracy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OjkLxGDo0fYp",
        "colab_type": "text"
      },
      "source": [
        "Importamos el paquete relevante que necesitamos para hacer la visualización"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SmsfR8Dt0fYt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFkqpGL30fYx",
        "colab_type": "text"
      },
      "source": [
        "Queremos visualizar la pérdida de entrenamiento (training loss) y la pérdida de validación (validation loss) de esta manera:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FN5UVswS0fYy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(hist.history['loss'])\n",
        "plt.plot(hist.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1jrZduwc0fY1",
        "colab_type": "text"
      },
      "source": [
        "También podemos visualizar la precisión del entrenamiento (training accuracy) y la precisión de la validación (validation accuracy) de esta manera:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vRpmq1y90fY4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(hist.history['acc'])\n",
        "plt.plot(hist.history['val_acc'])\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Val'], loc='lower right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}